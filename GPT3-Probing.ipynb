{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0c697ed",
   "metadata": {},
   "source": [
    "# Prompt Engineering and Probing with GPT3\n",
    "\n",
    "For the extra-credit, we will be exploring the recent trend that has revolutionalized this field. With GPT3, we can do a variety of tasks without the need of training a model. All we need to do is convert the task into an text generation task that follows a set of instructions called *prompts*. As an example, the task of sentiment classification can be designed as:\n",
    "\n",
    "```\n",
    "Decide whether a Tweet's sentiment is positive, neutral, or negative.\n",
    "\n",
    "Tweet: I loved the new Batman movie!\n",
    "Sentiment:\n",
    "```\n",
    "\n",
    "The GPT3 model then completes the text above with the response **Positive**. The above prompt is an example of zero-shot learning, meaning, we are not providing any signal/direction that can guide the decision and merely rely on GPT's pretraining objective:\n",
    "\n",
    "```\n",
    "Decide whether a Tweet's sentiment is positive, neutral, or negative.\n",
    "\n",
    "Tweet: I really liked the Spiderman movie!\n",
    "Sentiment: Positive\n",
    "\n",
    "Tweet: I loved the new Batman movie!\n",
    "Sentiment:\n",
    "```\n",
    "\n",
    "Now this is an example of 1-shot learning, i.e., you are providing an labeled example of how the output should look and then ask GPT to complete the next example. When you use more than 1 labeled example, it is known as few-shot learning.  Generally, if you provide more examples in the prompt, it will make better predictions.\n",
    "\n",
    "## Getting Started\n",
    "\n",
    "\n",
    "In this assignment, we will first need to register for an account at: https://platform.openai.com/ As a free trial, you will get $18 credits to make api calls to the GPT server. Once registered, you should go through the docs here: https://platform.openai.com/docs/guides/completion/prompt-design to get more info on the capabilities of the model. \n",
    "\n",
    "You can either do this homework using the free to use playground/chat interface of openai using the following links:\n",
    "\n",
    "- [https://platform.openai.com/playground](https://platform.openai.com/playground)\n",
    "- [https://chat.openai.com](https://chat.openai.com)\n",
    "\n",
    "But if you want to use the API to make automatic calls to open ai, we will need to follow the steps below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "806993a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Obtaining dependency information for openai from https://files.pythonhosted.org/packages/69/95/22a9a81cebd54e18841da429f05f06ed867648768f7af938ad34f13197fd/openai-1.3.3-py3-none-any.whl.metadata\n",
      "  Downloading openai-1.3.3-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting anyio<4,>=3.5.0 (from openai)\n",
      "  Obtaining dependency information for anyio<4,>=3.5.0 from https://files.pythonhosted.org/packages/19/24/44299477fe7dcc9cb58d0a57d5a7588d6af2ff403fdd2d47a246c91a3246/anyio-3.7.1-py3-none-any.whl.metadata\n",
      "  Downloading anyio-3.7.1-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Downloading distro-1.8.0-py3-none-any.whl (20 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from openai)\n",
      "  Obtaining dependency information for httpx<1,>=0.23.0 from https://files.pythonhosted.org/packages/82/61/a5fca4a1e88e40969bbd0cf0d981f3aa76d5057db160b94f49603fc18740/httpx-0.25.1-py3-none-any.whl.metadata\n",
      "  Downloading httpx-0.25.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/site-packages (from openai) (1.10.12)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/site-packages (from openai) (4.66.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.5 in /usr/local/lib/python3.11/site-packages (from openai) (4.8.0)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/site-packages (from anyio<4,>=3.5.0->openai) (3.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/site-packages (from anyio<4,>=3.5.0->openai) (1.3.0)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (2023.7.22)\n",
      "Collecting httpcore (from httpx<1,>=0.23.0->openai)\n",
      "  Obtaining dependency information for httpcore from https://files.pythonhosted.org/packages/56/ba/78b0a99c4da0ff8b0f59defa2f13ca4668189b134bd9840b6202a93d9a0f/httpcore-1.0.2-py3-none-any.whl.metadata\n",
      "  Downloading httpcore-1.0.2-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore->httpx<1,>=0.23.0->openai)\n",
      "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m998.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading openai-1.3.3-py3-none-any.whl (220 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m220.3/220.3 kB\u001b[0m \u001b[31m367.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading anyio-3.7.1-py3-none-any.whl (80 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.9/80.9 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0meta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading httpx-0.25.1-py3-none-any.whl (75 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m-:--:--\u001b[0m\n",
      "\u001b[?25hDownloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: h11, distro, anyio, httpcore, httpx, openai\n",
      "  Attempting uninstall: anyio\n",
      "    Found existing installation: anyio 4.0.0\n",
      "    Uninstalling anyio-4.0.0:\n",
      "      Successfully uninstalled anyio-4.0.0\n",
      "Successfully installed anyio-3.7.1 distro-1.8.0 h11-0.14.0 httpcore-1.0.2 httpx-0.25.1 openai-1.3.3\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/usr/local/opt/python@3.11/bin/python3.11 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f88e0fce-4d55-4fd3-9ea3-eeadefb11dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "## Find the API key by clicking on your profile in the openai page. Add the key to the environment as following:\n",
    "## Make sure to delete this cell afterwords\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = 'sk-...'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf90729c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "client.api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7fc7bd8-b70f-49d4-90ab-79b9eb63121b",
   "metadata": {},
   "source": [
    "## Using text completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bce117de",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.completions.create(\n",
    "  model=\"text-davinci-002\",\n",
    "  prompt=\"Decide whether a Tweet's sentiment is positive, neutral, or negative.\\n\\nTweet: \\\"I loved the new Batman movie!\\\"\\nSentiment:\",\n",
    "  temperature=0,\n",
    "  max_tokens=60,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0.5,\n",
    "  presence_penalty=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1900d9de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Completion(id='cmpl-8N1E8MuBQETzzOsWrgXVjnpL9MGht', choices=[CompletionChoice(finish_reason='stop', index=0, logprobs=None, text=' Positive')], created=1700496952, model='text-davinci-002', object='text_completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=1, prompt_tokens=31, total_tokens=32), warning='This model version is deprecated. Migrate before January 4, 2024 to avoid disruption of service. Learn more https://platform.openai.com/docs/deprecations')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6444ebbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Positive'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6245ed-ddba-469e-a5d4-85ce8a9e6513",
   "metadata": {},
   "source": [
    "## Using chat completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48670dc9-e5d1-4160-bebc-8bf7f9b27454",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a Sentiment Classifier.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Decide whether a Tweet's sentiment is positive, neutral, or negative.\\n\\nTweet: \\\"I loved the new Batman movie!\\\"\\nSentiment:\"}\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c85e3c05-e7de-4422-bc1c-eebcc802d3e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-8N1HzO3wnNW1QocJYp4Ox4r0JiwLI', choices=[Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='positive', role='assistant', function_call=None, tool_calls=None))], created=1700497191, model='gpt-3.5-turbo-0613', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=1, prompt_tokens=46, total_tokens=47))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23316601-6833-49ea-a487-5ce7433be9d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'positive'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd0af83",
   "metadata": {},
   "source": [
    "If you see ' Positive' as response in the above cell, you have successfully set-up gpt3 in your system.\n",
    "\n",
    "Now, the task for the assignment is really just do something cool. For example, you could probe how well GPT3 performs on the tasks in the previous HWs. Or, you could do something like question-answering or summarization, that were not covered in the assignments. The choice is yours."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31660025",
   "metadata": {},
   "source": [
    "## Submission\n",
    "\n",
    "Please submit a written report of what task you tried probing, how well did GPT3 do for that task and what were your key takeaways in this experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330bd30d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
